{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hin_BERT_coref_LSTM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zu9Y4N-flr9C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dd18cc1-7a9d-411a-fd42-82db0c470d92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.53)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWouTaP6mF3y"
      },
      "outputs": [],
      "source": [
        "# imports \n",
        "import re\n",
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpr9ao7rl4o0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acebea34-790c-4156-c128-caed9c025105"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# device = \"cpu\"\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "directory = '/content/hindi_coref_data'\n",
        "\n",
        "datasets = []\n",
        "for file in os.listdir(directory):\n",
        "    if file.endswith(\".csv\"):\n",
        "      df = pd.read_csv(os.path.join(directory, file))\n",
        "      datasets.append(df)\n",
        "\n",
        "print(len(datasets))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lnx_ezYGolLd",
        "outputId": "03b14133-9827-42ca-ad6a-b61b5a04cc62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "275\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = datasets[10]\n",
        "data.columns = [\"word\", \"cref\", \"crefHead\", \"acrefmod\", \"acrefmodHead\", \"crefmod\", \"creftype\", \"Chainhead\"]\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaSz9jUNos5C",
        "outputId": "f4b81f7c-e214-422a-b9d0-1f273cc3e1bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            word     cref        crefHead acrefmod acrefmodHead crefmod  \\\n",
            "0             के        _               _        _            _       _   \n",
            "1    मुख्यमंत्री  i2%1:t2  मुख्यमंत्री:i2        _            _   m1:i2   \n",
            "2        नरेंद्र  i3%0:t2               _        _            _       _   \n",
            "3           मोदी  i3%1:t2         मोदी:i3        _            _       _   \n",
            "4             के        _               _        _            _       _   \n",
            "..           ...      ...             ...      ...          ...     ...   \n",
            "344           का        _               _        _            _       _   \n",
            "345       नुकसान        _               _        _            _       _   \n",
            "346            न        _               _        _            _       _   \n",
            "347       पहुंचे        _               _        _            _       _   \n",
            "348            ।        _               _        _            _       _   \n",
            "\n",
            "                          creftype Chainhead  \n",
            "0                                _         _  \n",
            "1                                _         _  \n",
            "2                                _         _  \n",
            "3    Coreference-NounComplement:i2         _  \n",
            "4                                _         _  \n",
            "..                             ...       ...  \n",
            "344                              _         _  \n",
            "345                              _         _  \n",
            "346                              _         _  \n",
            "347                              _         _  \n",
            "348                              _         _  \n",
            "\n",
            "[349 rows x 8 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "# load the murilbert model\n",
        "path = 'google/muril-base-cased'\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(path)\n",
        "model = AutoModel.from_pretrained(path,\n",
        "                                  output_hidden_states=True # Whether the model returns all hidden-states.\n",
        "                                  ) \n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZTWpGEV3La-",
        "outputId": "80f5ef68-a4fe-4ae4-95a0-fffac562113b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/muril-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(197285, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(data, start):\n",
        "  # data is taken sentence wise, and stored in the texts array\n",
        "  texts = []\n",
        "  text = \"\"\n",
        "  tags = []\n",
        "  input_tokens = []\n",
        "\n",
        "  for i in range(start, len(data)):\n",
        "    if str(data[\"word\"][i]) == \"।\" :\n",
        "      text += str(data[\"word\"][i])\n",
        "      texts.append(text)\n",
        "      input_tokens += (tokenizer.convert_ids_to_tokens(tokenizer.encode(text)))\n",
        "      text = \"\"\n",
        "    else:\n",
        "      text += str(data[\"word\"][i]) + \" \"\n",
        "      tags.append(data[\"cref\"][i])\n",
        "\n",
        "  return texts, tags, input_tokens\n",
        "\n",
        "def get_word_vectors(texts):\n",
        "  \" function to get hindi word vectors from murilbert \"\n",
        "\n",
        "  outputs = []\n",
        "\n",
        "  for text in texts:\n",
        "    # encoded input with input ids, token type ids and attention mask\n",
        "    input_encoded = tokenizer.encode_plus(text, return_tensors=\"pt\")\n",
        "    # input_encoded.to(device)\n",
        "\n",
        "    # obtain and take the sum of all 13 states of BERT output\n",
        "    with torch.no_grad():\n",
        "            states = model(**input_encoded).hidden_states\n",
        "\n",
        "    output = torch.stack([states[i] for i in range(len(states))]).sum(dim = 0)\n",
        "    output = output.squeeze()\n",
        "    outputs.append(output)\n",
        "\n",
        "  return torch.cat(outputs, dim = 0)"
      ],
      "metadata": {
        "id": "0P6mqSCu7DyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# do this file wise\n",
        "def map_mentions(data, start):\n",
        "  \" function to make a list of mentions, along with a list of their corresponding cluster ids\"\n",
        "  mentions = []\n",
        "  mention_ids = [1]\n",
        "  mention = \"\"\n",
        "  count = 1\n",
        "  for i in range(start, len(data)):\n",
        "    tag = data[\"cref\"][i]\n",
        "    if (tag[0] == \"i\"):\n",
        "      idx = (re.search('i(\\d*)%', tag)).group(1)\n",
        "      mention_idx = (re.search('t(.*)', tag)).group(1) \n",
        "      if int(idx) == count:\n",
        "        mention += str(data[\"word\"][i]) + \" \"\n",
        "      else:\n",
        "        mentions.append(mention)\n",
        "        mention_ids.append(mention_idx)\n",
        "        mention = str(data[\"word\"][i]) + \" \"\n",
        "        count += 1\n",
        "\n",
        "  return mentions, mention_ids"
      ],
      "metadata": {
        "id": "Txwr4eMYIe5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getvec(output, mention):\n",
        "  \" function to get the vector of a mention, it takes the average of all word vectors in the mention \"\n",
        "  vec = torch.zeros(768)\n",
        "  tokens = tokenizer.convert_ids_to_tokens(tokenizer.encode(mention))\n",
        "  count = 1\n",
        "  for i in range(1, len(tokens) - 1):\n",
        "    try: \n",
        "      idx = input_tokens.index(tokens[i])\n",
        "    except:\n",
        "      idx = 1\n",
        "    # print(idx)\n",
        "    vec = vec.to(device)\n",
        "    vec = torch.add(vec, output[idx].to(device))\n",
        "    count += 1\n",
        "  \n",
        "  return torch.div(vec, count).to(device)"
      ],
      "metadata": {
        "id": "J2JTQ0NnIABN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_mention_pairs(embeds, mentions, mention_ids):\n",
        "  \" function to make a list of mention pairs and their true/false values \"\n",
        "  x_train = torch.empty(0).to(device)\n",
        "  y_train = torch.empty(0).to(device)\n",
        "\n",
        "  for i in range(len(mentions)):\n",
        "    for j in range(i + 1, len(mentions)):\n",
        "      x_train = torch.cat((x_train, (getvec(embeds, mentions[i]) + getvec(embeds, mentions[j]))) , 0)\n",
        "      if mention_ids[i] == mention_ids[j]:\n",
        "        y_train = torch.cat((y_train, torch.tensor([1]).to(device)))\n",
        "      else:\n",
        "        y_train = torch.cat((y_train, torch.tensor([0]).to(device)))\n",
        "\n",
        "  x_train = x_train.reshape(-1, 768)\n",
        "\n",
        "  return x_train, y_train"
      ],
      "metadata": {
        "id": "xEKNQn1sKRd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "class Lstm(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Lstm, self).__init__()\n",
        "        self.embedding_dim = 768\n",
        "        self.num_layers = 2\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=self.embedding_dim,\n",
        "            hidden_size=self.embedding_dim,\n",
        "            num_layers=self.num_layers,\n",
        "            dropout=0.2,\n",
        "        )\n",
        "        \n",
        "    def forward(self, x, prev_state):\n",
        "        embed = x\n",
        "        output, state = self.lstm(embed, prev_state)\n",
        "        return output, state\n",
        "\n",
        "    def init_state(self, sequence_length):\n",
        "        return (torch.zeros(self.num_layers,1, self.embedding_dim),\n",
        "                torch.zeros(self.num_layers,1, self.embedding_dim))"
      ],
      "metadata": {
        "id": "hM4E0WDLBiht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining the network\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "class BC_Model(nn.Module):\n",
        "  def __init__(self,input_shape):\n",
        "    super(BC_Model,self).__init__()\n",
        "    self.fc1 = nn.Linear(input_shape,32)\n",
        "    self.fc2 = nn.Linear(32,64)\n",
        "    self.fc3 = nn.Linear(64,1)  \n",
        "  \n",
        "  def forward(self,x): \n",
        "    # print(x.shape)\n",
        "    x = torch.relu(self.fc1(x))\n",
        "    x = torch.relu(self.fc2(x))\n",
        "    x = torch.sigmoid(self.fc3(x))\n",
        "    return x"
      ],
      "metadata": {
        "id": "u0sg46kzL5Iw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining dataset class\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "class dataset(Dataset):\n",
        "  def __init__(self,x,y):\n",
        "    self.x = torch.tensor(x,dtype=torch.float32)\n",
        "    self.y = torch.tensor(y,dtype=torch.float32)\n",
        "    self.length = self.x.shape[0]\n",
        " \n",
        "  def __getitem__(self,idx):\n",
        "    return self.x[idx],self.y[idx]  \n",
        "\n",
        "  def __len__(self):\n",
        "    return self.length"
      ],
      "metadata": {
        "id": "LoCtGaqONIc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hyper parameters\n",
        "learning_rate = 0.01\n",
        "epochs = 2\n",
        "\n",
        "# Models , Optimizer, Loss\n",
        "lstm = Lstm().to(device)\n",
        "bc_model = BC_Model(input_shape=768).to(device)\n",
        "optimizer1 = torch.optim.SGD(bc_model.parameters(), lr=learning_rate)\n",
        "optimizer2 = optim.Adam(lstm.parameters(), lr=learning_rate)\n",
        "loss_fn = nn.BCELoss()"
      ],
      "metadata": {
        "id": "PQsdb0t9R3cU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "  # mentions, mention_ids = map_mentions(data, 0)\n",
        "  # x, y = make_mention_pairs(bert_embeddings, mentions, mention_ids)\n",
        "  # print(x.shape, y.shape)\n",
        "  # trainset = dataset(x,y)\n",
        "  # trainloader = DataLoader(trainset,batch_size=64,shuffle=False)"
      ],
      "metadata": {
        "id": "cBl-EgqzI5Fq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(data, embeds, epochs):\n",
        "  lstm.train()\n",
        "  bc_model.train()\n",
        "  \n",
        "  mentions, mention_ids = map_mentions(data, 0)\n",
        "  running_loss = 0\n",
        "  prev_loss = 0\n",
        "  for epoch in range(epochs):\n",
        "    optimizer1.zero_grad()\n",
        "    optimizer2.zero_grad()\n",
        "    # get the lstm embeddings \n",
        "    state_h, state_c = lstm.init_state(0)\n",
        "    outputs = []\n",
        "    # loop over all the embeddings and pass them through the lstm\n",
        "    for i in range(len(embeds)):\n",
        "      # print(i, embeds[i][:2])\n",
        "      y_pred, (state_h, state_c) = lstm(embeds[i].view(1, 1, -1), (state_h, state_c))\n",
        "      outputs.append(state_h[0][0])\n",
        "  \n",
        "    # outputs contains the lstm embeds, use these to get the new embeds and pass them through the binary classifier\n",
        "    running_loss = 0\n",
        "\n",
        "    # train loader should have output embeds from lstm\n",
        "    \n",
        "    x, y = make_mention_pairs(outputs, mentions, mention_ids)\n",
        "    trainset = dataset(x,y)\n",
        "    trainloader = DataLoader(trainset,batch_size=64,shuffle=False)\n",
        "\n",
        "    for j,(x_train,y_train) in enumerate(trainloader):\n",
        "    \n",
        "      #calculate output\n",
        "      output = bc_model(x_train)\n",
        "  \n",
        "      #calculate loss\n",
        "      loss = loss_fn(output,y_train.reshape(-1,1))\n",
        "\n",
        "      #backprop\n",
        "      loss.backward()\n",
        "      optimizer1.step()\n",
        "      optimizer2.step()\n",
        "\n",
        "      running_loss += loss.item()\n",
        "\n",
        "    avg_loss = running_loss/ len(trainloader)\n",
        "    print(\"epoch {}\\tloss : {}\".format(epoch,avg_loss))"
      ],
      "metadata": {
        "id": "yRUS2sKE7wA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for data in datasets[1:2]:\n",
        "  data.columns = [\"word\", \"cref\", \"crefHead\", \"acrefmod\", \"acrefmodHead\", \"crefmod\", \"creftype\", \"Chainhead\"]\n",
        "  texts, tags, input_tokens = prepare_data(data, 0)\n",
        "  # print(len(tags))\n",
        "  bert_embeddings = get_word_vectors(texts)\n",
        "  print(bert_embeddings.shape)\n",
        "  train(data, bert_embeddings, 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KKwo9YFW7qN",
        "outputId": "0be598be-645e-4b33-e01d-0523916a6c81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([524, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0\tloss : 0.17533620144240558\n",
            "epoch 1\tloss : 0.16641665160256838\n",
            "epoch 2\tloss : 0.16221322411937372\n",
            "epoch 3\tloss : 0.1494382724132655\n",
            "epoch 4\tloss : 0.16034334113854648\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "QsZfWmEqTwFs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lstm_output(embeds, lstm, data):\n",
        "  lstm.eval()\n",
        "\n",
        "  state_h, state_c = lstm.init_state(0)\n",
        "  outputs = []\n",
        "  # loop over all the embeddings and pass them through the lstm\n",
        "  for i in range(len(embeds)):\n",
        "    y_pred, (state_h, state_c) = lstm(embeds[i].view(1, 1, -1), (state_h, state_c))\n",
        "    outputs.append(state_h[0][0])\n",
        "    \n",
        "  return outputs"
      ],
      "metadata": {
        "id": "mfPWokiPUoKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = torch.empty(0).to(device)\n",
        "y_test = torch.empty(0).to(device)\n",
        "\n",
        "for data2 in datasets[223:224]:\n",
        "  try:\n",
        "    data2.columns = [\"word\", \"cref\", \"crefHead\", \"acrefmod\", \"acrefmodHead\", \"crefmod\", \"creftype\", \"Chainhead\"]\n",
        "\n",
        "    texts, tags, input_tokens = prepare_data(data2, 0)\n",
        "\n",
        "    # print(len(texts), texts)\n",
        "    embeds = get_word_vectors(texts)\n",
        "    print(embeds.shape)\n",
        "\n",
        "    mentions, mention_ids = map_mentions(data2, 0)\n",
        "    outputs = lstm_output(embeds, lstm, data2)\n",
        "    print(len(outputs))\n",
        "    x, y = make_mention_pairs(outputs, mentions, mention_ids)\n",
        "    print(x.shape, y.shape)\n",
        "\n",
        "    x_test = torch.cat((x_test, x.to(device)))\n",
        "    y_test = torch.cat((y_test, y.to(device)))\n",
        "  except:\n",
        "    continue\n",
        "\n",
        "x_test = x_test.reshape(-1, 768)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t50GsFfdToV1",
        "outputId": "73d60a24-8c38-444c-8869-3471de611905"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([423, 768])\n",
            "423\n",
            "torch.Size([1891, 768]) torch.Size([1891])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testset = dataset(x_test,y_test)\n",
        "testloader = DataLoader(testset,batch_size=1,shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cpwcbjt0T7r8",
        "outputId": "a4188aa4-935b-412c-8815-476b1e871868"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_vals = []\n",
        "actual_vals = []\n",
        "bc_model.eval()\n",
        "\n",
        "for i,(x_test,y_test) in enumerate(testloader):\n",
        "  \n",
        "  #calculate output\n",
        "  output = bc_model(x_test)\n",
        "  print(output)\n",
        "  if output >= 0.028:\n",
        "    predicted_vals.append(1)\n",
        "  else:\n",
        "    predicted_vals.append(0)\n",
        "  actual_vals.append( int(y_test.item()) )\n",
        "\n",
        "predicted_vals = np.array(predicted_vals)\n",
        "actual_vals = np.array(actual_vals)"
      ],
      "metadata": {
        "id": "MEIOMVQfT9WA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# predicted_vals\n",
        "# actual_vals\n",
        "# accuracy: (tp + tn) / (p + n)\n",
        "accuracy = accuracy_score(actual_vals, predicted_vals)\n",
        "print('Accuracy: %f' % accuracy)\n",
        "# precision tp / (tp + fp)\n",
        "precision = precision_score(actual_vals, predicted_vals, average='weighted')\n",
        "print('Precision: %f' % precision)\n",
        "# recall: tp / (tp + fn)\n",
        "recall = recall_score(actual_vals, predicted_vals, average='weighted')\n",
        "print('Recall: %f' % recall)\n",
        "# f1: 2 tp / (2 tp + fp + fn)\n",
        "f1 = f1_score(actual_vals, predicted_vals, average='weighted')\n",
        "print('F1 score: %f' % f1)\n",
        " \n",
        "# confusion matrix\n",
        "matrix = confusion_matrix(actual_vals, predicted_vals)\n",
        "print(matrix)   "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lSKQcEHT_jb",
        "outputId": "6f90e6d5-8184-4aab-db2c-20cdfd9c2c30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.899524\n",
            "Precision: 0.809144\n",
            "Recall: 0.899524\n",
            "F1 score: 0.851943\n",
            "[[1701    0]\n",
            " [ 190    0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(roc_auc_score(actual_vals, predicted_vals))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YperSWdUA54",
        "outputId": "42468bc2-b611-4e33-8adb-2504c6ece1ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(bc_model, \"hin_coref_lstm\")"
      ],
      "metadata": {
        "id": "84bYw1rNUC5J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}